06.07.2024 Project Kick-Off
Isabella Docu, Ruslan PM, Zaur Contact Person

Monday meeting at 7pm 
another day tbd recap call

Week 1: Intro
Week 2: already real tickets

Role 1: PM 
Role 2: Documentation
Role 3: Contact Person

Filled availability tracking list, contacted Patrick for the dataset, created GitHub Repository, connected VS to GitHub schedule first call

VS Code and GitHub: 
- to add new file to repository: git add . (in Terminal)
- the get most recent repository from github repository to personal computer: git pull  (in Terminal)
- label changes: git commit --> open file to write a name for the change (e.g. change 1, etc.)  (in Terminal)
- to update the most recent repository from personal computer into the github repository: git push  (in Terminal)



10.07.2024 First meeting with Patrick
Topic: Fairness 

Data is always biased -> reason for this lies in the collection of data

essential aspect we want to look at in our data.--> data that can be biased from the target group
we are looking at loan data: features, target -> we want to focus our target

ask ourselves: what is our target --> if someone at the end of the desk decides if youre getting a loan or not, despite any models output --> How fair is this? 

in what terms of fairness?
27 definitions of fairness in machine learning --> can be found in the paper as well
we have to decide what we want to do to have a specific sort of fairness

Patrick expects: no standard analysis of the data, what taks do we have (classifier task) --> what methods can we use for this
how easy is this, is it fair?

Patrick has no ideal goal for us, he wants to see our weekly progress 

Patrick gives us all his knowledge and experience, we should present the problem as if the crowd would have identified the problem before us

1. read paper
2. choose method

we can decide how far we want to go, we can add more and more value if we want to like e.g. app or web interface; main ingredient point should be choosing the right model and look at the fairness aspect

set a weekly --> group proposes times to Patrick (1 hr / week)

try to make all 3 of us the same work, then prepare results --> if you cant make it then you cathc up with the others
first month like that, later we can check if we need to split the work

in parallel: everyone looks into one specific method and later explains it to the others --> then we choose which method / model we want to use

dataset itself is not that big, dont care so much about dataload and transformation, dataset is focused on content 

approx. 3-4 hours a week of workload

first part is more practitioner oriented, second part is rather theoretical, third part is combining the data modelling and the theory; we need to stretch it a little bit from the truth (?)


Meeting with Patrick 16.07.2024
•	What does the data offer –> broad analysis
•	What is our target
•	Is data balanced / inbalanced
•	Then we discuss which method we use for reaching the data

•	Choose a Classifier --> everyone should do this himself; in the end: is the score fair (we can do it in the meeting on Saturday?)
•	When we reached a score with a model, is the score good, can we improve it  Pandas to use data crunching / processing
•	Plot libraries to plot the data
•	Derive a hypothesis


20.07.2024 First Hackathon
1. cleaning of data
  1.1 delete unnecessary data
  1.2 decide what to do with missing values
2. basic analysis (mean, median, etc.)
  2.1 creation of boxplots for initial visualization
3. modeling
  3.1 choose 3 model types 
  3.2 and compare them (classifiers)
4. decide on a classifier
  4.1 create synthetic data to test the models
  4.2 compare results of the classifiers
5. check fairness
6. create project documentation / presentation

